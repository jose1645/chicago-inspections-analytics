{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "def load_model(bucket_name, model_path):\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=os.getenv('NOTEBOOK_ACCESS_KEY'),\n",
    "        aws_secret_access_key=os.getenv('NOTEBOOK_ACCESS_KEY_SECRET')\n",
    "    )   \n",
    "    response = s3_client.get_object(Bucket=bucket_name, Key=model_path)\n",
    "    model = pickle.loads(response['Body'].read())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(bucket_name, dataset_path):\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=os.getenv('NOTEBOOK_ACCESS_KEY'),\n",
    "        aws_secret_access_key=os.getenv('NOTEBOOK_ACCESS_KEY_SECRET')\n",
    "    ) \n",
    "    response = s3_client.get_object(Bucket=bucket_name, Key=dataset_path)\n",
    "    test_data = pickle.loads(response['Body'].read())\n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_predictions(model, test_data):\n",
    "    # Suponiendo que test_data es un DataFrame o una matriz que el modelo puede procesar\n",
    "    predictions_score = model.predict_proba(test_data)[:, 1]  # Obtener la probabilidad para la clase positiva\n",
    "    return predictions_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def save_predictions(predictions_score, bucket_name, save_path):\n",
    "    date = datetime.now()\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=os.getenv('NOTEBOOK_ACCESS_KEY'),\n",
    "        aws_secret_access_key=os.getenv('NOTEBOOK_ACCESS_KEY_SECRET')\n",
    "    )  \n",
    "    predictions_data = {\n",
    "        'date': date,\n",
    "        'predictions_score': predictions_score.tolist()  # Convertir a lista para guardar\n",
    "    }\n",
    "    # Guardar como pickle\n",
    "    pickle_data = pickle.dumps(predictions_data)\n",
    "    s3_client.put_object(Bucket=bucket_name, Key=save_path, Body=pickle_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def generate_roc(predictions_score, bucket_name, save_path):\n",
    "    # Generar la curva ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, predictions_score)  # y_true debe ser las etiquetas reales\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Graficar la curva ROC\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # Guardar la imagen en el bucket\n",
    "    plt.savefig('/tmp/roc.png')\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=os.getenv('NOTEBOOK_ACCESS_KEY'),\n",
    "        aws_secret_access_key=os.getenv('NOTEBOOK_ACCESS_KEY_SECRET')\n",
    "    )    \n",
    "    with open('/tmp/roc.png', 'rb') as f:\n",
    "        s3_client.put_object(Bucket=bucket_name, Key=save_path, Body=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def save_metrics(predictions_score, y_true, bucket_name, save_path):\n",
    "    # Generar las métricas\n",
    "    pred_labels = (predictions_score >= 0.5).astype(int)  # Usando threshold de 0.5\n",
    "    metrics = classification_report(y_true, pred_labels, output_dict=True)\n",
    "\n",
    "    # Convertir a un DataFrame y guardar como pickle\n",
    "    metrics_df = pd.DataFrame(metrics).transpose()\n",
    "    metrics_pickle = pickle.dumps(metrics_df)\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=os.getenv('NOTEBOOK_ACCESS_KEY'),\n",
    "        aws_secret_access_key=os.getenv('NOTEBOOK_ACCESS_KEY_SECRET')\n",
    "    ) \n",
    "    s3_client.put_object(Bucket=bucket_name, Key=save_path, Body=metrics_pickle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_threshold(bucket_name, threshold_path):\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=threshold_path)\n",
    "    threshold = pickle.loads(response['Body'].read())\n",
    "    return threshold\n",
    "\n",
    "def generate_labels(predictions_score, threshold, bucket_name, save_path):\n",
    "    pred_labels = (predictions_score >= threshold).astype(int)  # Generar etiquetas usando el threshold\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id=os.getenv('NOTEBOOK_ACCESS_KEY'),\n",
    "        aws_secret_access_key=os.getenv('NOTEBOOK_ACCESS_KEY_SECRET')\n",
    "    )  \n",
    "    labels_data = {'predictions_labels': pred_labels.tolist()}  # Convertir a lista\n",
    "    pickle_data = pickle.dumps(labels_data)\n",
    "    s3_client.put_object(Bucket=bucket_name, Key=save_path, Body=pickle_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['facility_type__facility_type_BANQUET HALL',\n",
       "       'facility_type__facility_type_Bakery',\n",
       "       'facility_type__facility_type_Catering',\n",
       "       'facility_type__facility_type_Children's Services Facility',\n",
       "       'facility_type__facility_type_GAS STATION',\n",
       "       'facility_type__facility_type_Golden Diner',\n",
       "       'facility_type__facility_type_Grocery Store',\n",
       "       'facility_type__facility_type_Hospital',\n",
       "       'facility_type__facility_type_Liquor',\n",
       "       'facility_type__facility_type_Long Term Care',\n",
       "       'facility_type__facility_type_School',\n",
       "       'facility_type__facility_type_Shared Kitchen',\n",
       "       'facility_type__facility_type_Shared Kitchen User (Long Term)',\n",
       "       'facility_type__facility_type_Special Event',\n",
       "       'facility_type__facility_type_TAVERN',\n",
       "       'facility_type__facility_type_Wholesale',\n",
       "       'facility_type__facility_type_daycare',\n",
       "       'facility_type__facility_type_mobile food',\n",
       "       'facility_type__facility_type_other',\n",
       "       'facility_type__facility_type_restaurant', 'risk__risk_all',\n",
       "       'risk__risk_high', 'risk__risk_low', 'risk__risk_medium',\n",
       "       'remainder__latitude', 'remainder__longitude', 'remainder__month',\n",
       "       'remainder__year', 'remainder__day_of_month', 'remainder__week_of_year',\n",
       "       'remainder__week_day', 'remainder__weekend', 'remainder__day_of_week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bucket_name=\"chicago-inspections-analytics\"\n",
    "model_path=\"selected-model/select_model.pkl\"\n",
    "dataset_path=\"dataset/test/test_dataset.pkl\"\n",
    "save_path_predictions=\"results/predictions_score.pkl\"\n",
    "save_path_ROC=\"results/roc.png\"\n",
    "save_path_predictions_table_metrics=\"results/metrics.pkl\"\n",
    "\n",
    "\n",
    "model=load_model(bucket_name, model_path)# Carga el modelo desde S3.\n",
    "datosprueba=load_test(bucket_name, dataset_path)# Carga el conjunto de datos de prueba desde S3.\n",
    "# Mostrar los nombres de las columnas\n",
    "datosprueba.columns\n",
    "\n",
    "\n",
    "#predictions_score=get_predictions(model, datosprueba)# Obtiene las predicciones del modelo en forma de scores (probabilidades).\n",
    "#save_predictions(predictions_score, bucket_name, save_path_predictions)# Guarda las predicciones junto con la fecha en S3.\n",
    "#generate_roc(predictions_score, bucket_name, save_path_ROC)# Genera la curva ROC y la guarda como imagen en S3.\n",
    "#save_metrics(predictions_score, y_true, bucket_name, save_path_predictions_table_metrics)# Genera las métricas y las guarda en S3.\n",
    "#generate_labels(predictions_score, threshold, bucket_name, save_path)# Genera las etiquetas con el threshold guardado y las guarda en S3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
